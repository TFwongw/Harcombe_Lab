{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongt\\AppData\\Roaming\\Python\\Python311\\site-packages\\nbformat\\__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    }
   ],
   "source": [
    "%run AFclass.ipynb\n",
    "import ast\n",
    "import itertools\n",
    "\n",
    "gr_DG = pd.read_csv('./r/data fitting/Data/gr_Div_DG_standardized_ByNoDrug.csv', index_col='Gene_inhibition')\n",
    "gr_DG.loc[:,:'S0_monoculture'][gr_DG.loc[:,:'S0_monoculture']<1e-5] = 0 \n",
    "\n",
    "label_df = pd.read_excel(open('./Data/iML1515_GP.xlsx', 'rb'), # ? S0 rct pathway label necessary?\n",
    "              sheet_name='iML1515_GP', index_col=0)\n",
    "# rct_pathway_df = pd.read_csv('./Data/rct_pathway.csv')\n",
    "# alpha_table = pd.read_csv(\"./Data/alpha_table.csv\", index_col=0)\n",
    "alpha_table = pd.read_csv(\"./Data/checkerboard_alpha_table.csv\", index_col=0)\n",
    "if len(alpha_table.columns) == 3:\n",
    "    alpha_table.columns = ['E0', 'S0.ac', 'S0.glc']\n",
    "else:\n",
    "    alpha_table.lv_pairs = alpha_table.lv_pairs.apply(ast.literal_eval)\n",
    "\n",
    "comb_list = list(pd.read_csv('./Data/gr_Div_DG_Blis_Aug31.csv').gene_inhibition[1:])\n",
    "DG_list = list(gr_DG.index)\n",
    "if 'Normal' in DG_list:\n",
    "    DG_list.remove('Normal')\n",
    "\n",
    "def convert_arg_to_list(arg):\n",
    "    if isinstance(arg, (pd.Series, pd.Index)):\n",
    "        arg = list(arg) \n",
    "    elif not isinstance(arg, (list, tuple, set)):\n",
    "        arg = [arg] # differ from list(arg) -> conversion of str\n",
    "    return arg\n",
    "\n",
    "def get_Biomass_df(files):\n",
    "    return pd.concat(\n",
    "            [pd.read_csv(file, index_col='cycle')\n",
    "             for file in convert_arg_to_list(files)]\n",
    "        ,axis=1)\n",
    "\n",
    "# Biomass_df = get_Biomass_df(['./Data/BM_SG1.csv', './Data/BM_DG1.csv'])\n",
    "Biomass_df = get_Biomass_df(['C:/Users/wongt/OneDrive/COMETS_Jupyter/Run_Comets/r/data fitting/Data/checkerboard_run3.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step=5\n",
    "\n",
    "def search_gr_cycle_with_biomass(df_search, biomass_values):\n",
    "    return [df_search[df_search >= biomass_value].idxmin() \n",
    "                for biomass_value in list(biomass_values)]\n",
    "\n",
    "def get_maximum_growth_cycle(desired_BM):\n",
    "    c_max_gr = desired_BM.iloc[1]+ (desired_BM.iloc[-1] - desired_BM.iloc[1])/2\n",
    "    bool_growing = ((desired_BM.iloc[-1]-desired_BM.iloc[-5])/desired_BM.iloc[-1]).apply(lambda x: x > 1e-10)\n",
    "    for k, bool_grow in bool_growing.items():\n",
    "        if bool_grow:\n",
    "            c_max_gr[k] = desired_BM[k].iloc[-6]\n",
    "    biomass_diff = (desired_BM.iloc[-1]-desired_BM.iloc[0])\n",
    "    start = desired_BM.iloc[0] + biomass_diff*0.1\n",
    "    end = desired_BM.iloc[0] + biomass_diff*0.9\n",
    "    return c_max_gr, start, end, bool_growing\n",
    "\n",
    "# def find_down_neighbour(df):\n",
    "#     max_gr = get_cycle_max_gr(df)\n",
    "#     position = list()\n",
    "    \n",
    "#     def correct_cycle(cycle):\n",
    "#         mod = cycle%log_step\n",
    "# #         return cycle if mod==0 else cycle+log_step-mod # round up\n",
    "#         return cycle if mod==0 else cycle-mod # round down\n",
    "# #   \n",
    "#     gr_cycle = defaultdict(dict)\n",
    "#     for gcomb, biomass_value in max_gr.items():\n",
    "#         df_search = df.loc[:,gcomb]\n",
    "#         upperneighbour_ind =  search_gr_cycle_with_biomass(df_search, biomass_value) # 0 if growth belolw 1e-8 \n",
    "# #         gr_cycle[gcomb] = correct_cycle(upperneighbour_ind) \n",
    "#         gr_cycle[gcomb].update({'cycle': correct_cycle(upperneighbour_ind),\n",
    "#                                 'growth phase': [search_gr_cycle_with_biomass(),\n",
    "#                                                 search_gr_cycle_with_biomass()]})\n",
    "#     return gr_cycle\n",
    "\n",
    "# def get_desired_cycle_df():\n",
    "#     desired_cycle_dict = defaultdict(dict)\n",
    "#     for k, cycle in find_down_neighbour(Biomass_df).items():\n",
    "#         key_items = k.split('_')\n",
    "#         gcomb = key_items.pop(1)\n",
    "#         col_name = '_'.join(key_items)\n",
    "#         if desired_cycle_dict[gcomb].get(col_name):\n",
    "#             sys.exit(\"Halt, Gene comb keys get overwritten\")\n",
    "#         desired_cycle_dict[gcomb].update({col_name: cycle})\n",
    "\n",
    "#     return pd.DataFrame.from_dict(desired_cycle_dict, orient='index')\n",
    "\n",
    "\n",
    "def get_desired_cycle(Biomass_df, log_step=5):\n",
    "    def correct_cycle(cycle): # \n",
    "        if cycle < log_step:\n",
    "            return log_step\n",
    "        return round(cycle / log_step) * log_step\n",
    "\n",
    "    def get_growth_phase_length():\n",
    "        return ((desired_cycle['end'] - desired_cycle['start'])*(1-desired_cycle.bool_growing) + # if not growing, not changing growth phase length\n",
    "                1e4*(desired_cycle.bool_growing)) #if growing, set growth length to 999\n",
    "    \n",
    "    def split_index_to_cols(df):\n",
    "        items = df.index.str.split('_')\n",
    "        columns = ['Species', 'Gene_inhibition', 'culture']\n",
    "        if len(items[0]) > 3:\n",
    "            columns.extend(['alpha_lv_pairs'])\n",
    "        return pd.DataFrame(items.tolist(), index=df.index, columns=columns)\n",
    "    desired_biomass_df = pd.DataFrame(get_maximum_growth_cycle(Biomass_df), index=['c_max_gr', 'start', 'end', 'bool_growing'])\n",
    "    \n",
    "    desired_cycle = (desired_biomass_df.iloc[:-1]\n",
    "                .apply(lambda x: \n",
    "                        search_gr_cycle_with_biomass(Biomass_df.loc[:,x.name],x))\n",
    "                .T)\n",
    "    desired_cycle['bool_growing'] = desired_biomass_df.T.bool_growing\n",
    "    desired_cycle['cycle_max_gr'] = desired_cycle['c_max_gr'].apply(correct_cycle) # -> cycle_max_gr\n",
    "    desired_cycle['growth_phase'] = desired_cycle[['start', 'end']].values.tolist()\n",
    "    desired_cycle['growth_phase_length'] = get_growth_phase_length()\n",
    "    desired_cycle['end_cycle'] = Biomass_df.index[-1]//5*5\n",
    "    desired_cycle = desired_cycle.join(split_index_to_cols(desired_cycle))\n",
    "#     .query('culture==\"coculture\"')\n",
    "    if len(desired_cycle.Gene_inhibition.unique()) >1:\n",
    "        desired_cycle = desired_cycle.set_index('Gene_inhibition')[['cycle_max_gr', 'bool_growing', 'growth_phase','growth_phase_length', 'Species','culture','end_cycle']]\n",
    "    else:\n",
    "        desired_cycle.index = ['_'.join([x[1],x[3]]) for x in desired_cycle.index.str.split('_')]\n",
    "        desired_cycle.Gene_inhibition = desired_cycle.index\n",
    "\n",
    "    return desired_cycle     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cycle = get_desired_cycle(Biomass_df, log_step=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract flux at maximum growth cycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_id(model, gene_name):\n",
    "    for i in model.genes:\n",
    "        if(i.name == gene_name):\n",
    "            return(i.id)\n",
    "\n",
    "def get_rcts_list(model, gcomb_list): \n",
    "    rcts_list = list()\n",
    "    rcts_set = set()\n",
    "    for i, gene in enumerate(gcomb_list):\n",
    "        gene_rcts = [rct.id for rct in model.genes.get_by_id(get_gene_id(model, gene)).reactions]\n",
    "        if i > 0:\n",
    "            gene_rcts = list(set(gene_rcts) - rcts_set)\n",
    "        rcts_list.append(gene_rcts)\n",
    "        rcts_set = rcts_set | set(gene_rcts)\n",
    "    return rcts_list\n",
    "\n",
    "def adjust_flux_df(model, df, gene_combo: list, alpha_table=alpha_table): \n",
    "    # Don't use v1 cols to indicate gene_inhibition, will skip unidirectional reaction\n",
    "    def query_alpha(gene_combo, alpha_table):\n",
    "        splitted = gene_combo.split('.')\n",
    "        if len(splitted) == 2:\n",
    "            gcomb_alpha = {gene: alpha_table.loc[gene, f'{model.id}'] for gene in gene_combo.split('.')}\n",
    "            # return gcomb_alpha\n",
    "\n",
    "        # alphas\n",
    "        splitted = gene_combo.split('_')\n",
    "        Gene_inhibition, lv_pair = [ele.split('.') for ele in 'folP.folA_1.2'.split('_')]\n",
    "        lv_pair = tuple([int(ele) for ele in lv_pair])\n",
    "        gcomb_alpha = dict()\n",
    "        alpha_table = alpha_table.query('lv_pairs == @lv_pair')\n",
    "        for current_gene in Gene_inhibition:\n",
    "            # print(alpha_table.head())\n",
    "            gcomb_alpha.update({current_gene: \n",
    "                                alpha_table.loc[current_gene, f'{model.id}']})\n",
    "        return gcomb_alpha, alpha_table\n",
    "\n",
    "    print(gene_combo)\n",
    "\n",
    "\n",
    "    if 'Normal' not in gene_combo:\n",
    "#         gene_combo_dict = get_gcomb_alpha_dict(gene_combo) \n",
    "        v1_cols = df.filter(regex='v1').columns\n",
    "        \n",
    "        # gcomb_alpha = {gene: alpha_table.loc[gene, f'{model.id}'] for gene in gene_combo.split('.')}\n",
    "        gcomb_alpha, alpha_table = query_alpha(gene_combo, alpha_table)\n",
    "        # print(gcomb_alpha)\n",
    "        gcomb_alpha = dict(sorted(gcomb_alpha.items(), key=lambda item: item[1], reverse=True))\n",
    "        \n",
    "        rcts_list = get_rcts_list(model, gcomb_alpha.keys()) # exclude repeated rct for two gene\n",
    "        scaled_rcts = list()\n",
    "\n",
    "        for gene, rcts in zip(gcomb_alpha.keys(), rcts_list):  \n",
    "#             rcts = [rct for rct in rcts if rct in orig_cols]\n",
    "            for orig_col in rcts:\n",
    "                alpha = alpha_table.loc[f'{gene}', f'{model.id}']    \n",
    "                v1_col = orig_col + \"_v1\"\n",
    "                reversible = v1_col  in v1_cols\n",
    "                if reversible: \n",
    "                    df[f'{orig_col}'] = (df[f'{orig_col}'] + df[f'{v1_col}'])/alpha # only forward or backward != 0  \n",
    "                    df = df.drop(f'{v1_col}', axis=1)  \n",
    "                else:\n",
    "                    df[f'{orig_col}'] = (df[f'{orig_col}'])/alpha # only forward or backward != 0              \n",
    "    return df\n",
    "\n",
    "def get_desired_BM(Biomass_df = Biomass_df, regex='Normal_coculture'):\n",
    "    return Biomass_df.filter(regex=regex)\n",
    "  \n",
    "def supply_line(file):\n",
    "#     file = f'./Data/{file}'\n",
    "    with open(file) as fh:\n",
    "        for line in fh:\n",
    "            yield json.loads(line) \n",
    "\n",
    "def retrive_specific_culture(file_list: list, culture_item: str, XG = 'DG'): # culture items:'coculture_media', 'E0_coculture_flux', 'S0_ac_coculture_flux', 'E0_monoculture_media', 'E0_monoculture_flux', 'S0_ac_monoculture_media', 'S0_ac_monoculture_flux'\n",
    "    def modify_culture_dict_keys(k: str, XG: str):\n",
    "        if k!='coculture_media':\n",
    "            k_list = k.split('_')\n",
    "            k_list[:-2] =  ['.'.join(k_list[:-2])]\n",
    "            k_list.append(XG)\n",
    "        else: \n",
    "            k_list = [k, XG]\n",
    "        return '_'.join(k_list)\n",
    "\n",
    "    flux_dict = dict()\n",
    "    coculture_dict = dict()\n",
    "    file_list, XG = convert_arg_to_list(file_list), convert_arg_to_list(XG)\n",
    "\n",
    "    for file, current_XG in itertools.zip_longest(file_list, XG, fillvalue=None):\n",
    "        if file is not None: # get SG DG flux from sasme json file\n",
    "            supp = supply_line(file)\n",
    "           \n",
    "        # prefix in json \n",
    "        culture_items = [f'E0_{culture_item}', f'S0_{culture_item}'] if culture_item != 'coculture_media' else [culture_item]\n",
    "        for line in supp:    # culture as column <=> keys\n",
    "    #         coculture_dict = line.get(f'{culture_item}')\n",
    "            if any([ele in line.keys() for ele in culture_items]):\n",
    "                coculture_dict.update(\n",
    "                    {modify_culture_dict_keys(k, current_XG): v \n",
    "                     for k, v in line.items() if k in culture_items}) \n",
    "    return coculture_dict # {E0_coculture: Dict, S0_coculture: Dict}\n",
    "\n",
    "# pwy group with more than 2 element\n",
    "def get_pwypair_gp_GRT2(p_o: dict): # index greater than 2 element\n",
    "    flux_compare_combos_dict = {k:v for k,v in p_o.items() if len(v)>=2}\n",
    "    return flux_compare_combos_dict\n",
    "\n",
    "def remove_Zero_col(df): # extend N differ than 0 \n",
    "    return(df.loc[:, ((df !=0) & (df.notnull())).any(axis=0)]) # ignore NA entry \n",
    "\n",
    "def clean_flux_df(df):\n",
    "    return remove_Zero_col(df.dropna())\n",
    "\n",
    "def get_XG_cycle_from(desired_cycle):\n",
    "\n",
    "    if len(desired_cycle.index[-1].split('.')) <=2:\n",
    "        SG_cycle = desired_cycle.loc[[len(ele.split('.')) ==1 for ele in desired_cycle.index]]\n",
    "        DG_cycle = desired_cycle.loc[[len(ele.split('.')) ==2 for ele in desired_cycle.index]]\n",
    "    else:\n",
    "        SG_cycle = desired_cycle.loc[['0' in ele for ele in desired_cycle.index]]\n",
    "        DG_cycle = desired_cycle.loc[['0' not in ele for ele in desired_cycle.index]]\n",
    "    SG_cycle.index.name='SG'\n",
    "    DG_cycle.index.name='DG'\n",
    "    SG_cycle.columns.name=None\n",
    "    DG_cycle.columns.name=None\n",
    "    return SG_cycle, DG_cycle    \n",
    "\n",
    "# def get_SG_DG(explode=True):\n",
    "#     df = pd.DataFrame(pd.DataFrame(2*[DG_list], index=['Gene_inhibition','SG']).T.set_index('Gene_inhibition').SG.str.split('.'))\n",
    "#     return df.explode('SG') if explode else df\n",
    "   \n",
    "# def get_alpha_wide(alpha_table):\n",
    "#     S = [ele for ele in alpha_table.columns if 'S0' in ele]\n",
    "#     return alpha_table.melt(value_vars=[E0.id, S[0]], var_name='Species', value_name='alpha', ignore_index=False)\n",
    "\n",
    "# def get_alpha_to_merge(alpha_table):\n",
    "#     def get_alpha(l: list[str, str], alpha_table):\n",
    "#         l=l[0]\n",
    "#     #     print(l)\n",
    "#         Species = [E0.id, S0.id]\n",
    "#         df = pd.DataFrame(alpha_table.loc[l, Species]).T\n",
    "#         return df.values.tolist()\n",
    "#     # a.apply(get_alpha, axis=1, result_type='broadcast')\n",
    "\n",
    "#     S = [ele for ele in alpha_table.columns if 'S0' in ele]\n",
    "#     ES_cols = ['E0', S[0]]\n",
    "#     alpha_wide = get_alpha_wide(alpha_table)\n",
    "#     df = (get_SG_DG(explode=False)\n",
    "#           .apply(lambda x: pd.Series(get_alpha(x, alpha_table), index=ES_cols), axis=1) # df with E0 S0 alpha columns\n",
    "#           .melt(value_vars=ES_cols, var_name='Species', value_name='alpha', ignore_index=False)\n",
    "#           .combine_first(alpha_wide))\n",
    "#     return df\n",
    "# alpha_to_merge = get_alpha_to_merge(alpha_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_growth_phase_summary(model, culture, df_from_js, desired_cycle, current_gene_combo, is_flux=True):\n",
    "    \n",
    "    growth_phase = desired_cycle.query('Species == @model.id & culture == @culture').loc[current_gene_combo, 'growth_phase']\n",
    "    print(growth_phase)\n",
    "    growth_df = df_from_js.query('cycle>@growth_phase[0] & cycle<@growth_phase[1]').drop('cycle', axis=1)\n",
    "#     growth_df = growth_df.drop(['cycle','x','y'], axis=1) if is_flux else growth_df.drop(['cycle','x','y'])\n",
    "    summary_df = (growth_df.apply(['mean','std'])\n",
    "         .unstack().to_frame().T)\n",
    "    summary_df.columns = summary_df.columns.map('_'.join).str.strip('_')\n",
    "    summary_df.index= [current_gene_combo]\n",
    "    return summary_df\n",
    "\n",
    "def retrive_specific_keys(model, file, culture_item, desired_cycle, desired_cycle_col='cycle_max_gr',alpha_table=alpha_table):\n",
    "    # ?convert to apply function speed up?\n",
    "    # INDEX in desired_cycle determines SG/DG list to query \n",
    "    def get_flux_dict(coculture_dict, model, desired_cycle, desired_cycle_col=desired_cycle_col):\n",
    "#         if model.id in coculture_dict.keys(): # ?delete?\n",
    "#             coculture_dict = coculture_dict[model.id]x\n",
    "        flux_dict, no_grow = dict(), list()\n",
    "        culture = culture_item.split('_')[0]\n",
    "#         item_is_flux = culture_item.split('_')[1] == 'flux'\n",
    "#         for current_gene_combo, cycle in desired_cycle[[f'{model.id}_{culture}']].iterrows():\n",
    "#         print(desired_cycle.query('Species == @model.id & culture == @culture').index)\n",
    "        for current_gene_combo, cycle_row in desired_cycle.query('Species == @model.id & culture == @culture').iterrows():\n",
    "            # print(current_gene_combo, cycle_row)\n",
    "            \n",
    "            cycle = cycle_row[desired_cycle_col] # iterrow create subdata frame of one column \n",
    "            \n",
    "            print('ccyc', cycle)\n",
    "            if cycle < 10:\n",
    "                no_grow.append(current_gene_combo)\n",
    "                flux_dict[current_gene_combo] = pd.DataFrame(index = [f'{current_gene_combo}'])\n",
    "            else:\n",
    "                desired_js = coculture_dict.get(f'{current_gene_combo}') if type(coculture_dict) is dict else coculture_dict[current_gene_combo]\n",
    "                # coculture_dict['E0_monoculture_flux_SG']['folP.folA_1.0']\n",
    "                # df_from_js = pd.read_json(desired_js)\n",
    "                df_from_js = pd.DataFrame.from_dict(desired_js)\n",
    "                is_flux = '_flux' in culture_item\n",
    "                if is_flux:\n",
    "                    df_from_js = adjust_flux_df(model, df_from_js, current_gene_combo,alpha_table).drop(['x','y'], axis=1)\n",
    "                    \n",
    "                else:\n",
    "                    df_from_js = df_from_js.pivot(index=['cycle'],columns=['metabolite'], values='conc_mmol').reset_index()\n",
    "                growth_phase_summary = get_growth_phase_summary(model, culture, df_from_js, desired_cycle, current_gene_combo, is_flux=is_flux)\n",
    "                \n",
    "                temp_df = df_from_js.query(\"cycle == @cycle\")\n",
    "\n",
    "                print(temp_df.cycle, current_gene_combo, cycle_row, cycle)\n",
    "\n",
    "#                 if '_media' in culture_item:\n",
    "#                     temp_df = temp_df.set_index(['metabolite','cycle']).drop(['x','y'],axis=1).unstack([0]).conc_mmol.reset_index() # media stored as stacked form \n",
    "                temp_df.index = [current_gene_combo]\n",
    "        #                 return temp_df, current_gene_combo\n",
    "                temp_df = pd.concat([temp_df, growth_phase_summary], axis=1) # mean, sd for each reaction -> ncols*3\n",
    "                \n",
    "                flux_dict[current_gene_combo] = temp_df # df as \n",
    "        #             genes_dict = {current_gene_combo: genes_dict.get(f'{current_gene_combo}') for current_gene_combo in genes_dict}  #subset of gene\n",
    "        if no_grow:\n",
    "            print('Zero growth: ', ', '.join(no_grow))\n",
    "        return pd.concat(flux_dict.values()).copy() # pd.read_json() culture_item -> col pd.read_json()\n",
    "#         return pd.concat(flux_dict.values()) # pd.read_json() culture_item -> col pd.read_json()\n",
    "    \n",
    "#     print(type(file) is dict)\n",
    "    if type(file) in [dict, pd.DataFrame, pd.Series]:\n",
    "        return get_flux_dict(file, model, desired_cycle)\n",
    "    else: # list of filename, str filename\n",
    "        coculture_dict = retrive_specific_culture(file, culture_item)\n",
    "        return get_flux_dict(coculture_dict, model, desired_cycle) \n",
    "    \n",
    "def set_GI_SP_as_MI(end_BM, manual_SI = False, multi_index = None):\n",
    "    if type(end_BM.index[0]) is not int: # Gene_inhibition is not index # Series.dtype -> dtype('int64')\n",
    "        if end_BM.index.name in [None, 'DG']:\n",
    "            end_BM.index.name = 'Gene_inhibition'\n",
    "        if end_BM.index.name == 'Gene_inhibition':\n",
    "            if 'Gene_inhibition' in end_BM.columns:\n",
    "                end_BM = end_BM.drop('Gene_inhibition', axis=1)\n",
    "            end_BM = end_BM.reset_index()\n",
    "    if multi_index:\n",
    "        return end_BM.set_index(multi_index)\n",
    "    if 'Species' in end_BM.columns and manual_SI == False:\n",
    "        return end_BM.set_index(['Gene_inhibition', 'Species'])\n",
    "    else:\n",
    "        return end_BM.set_index('Gene_inhibition')\n",
    "\n",
    "# def join_dfs_using_MI(df1, df2, how='left'):\n",
    "#     return set_GI_SP_as_MI(df1).join(set_GI_SP_as_MI(df2), how=how)\n",
    "\n",
    "def join_dfs_using_MI(df_list, how='left', multi_index = None):\n",
    "    df_list = [set_GI_SP_as_MI(df, multi_index=multi_index) for df in df_list]\n",
    "    result_df = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        result_df = result_df.join(df, how=how)\n",
    "    return result_df\n",
    "\n",
    "def get_flux_compare_df(culture_item, coculture_dict=None, desired_cycle_col='cycle_max_gr', desired_cycle = desired_cycle, alpha_table=alpha_table): # also work for extracting metabolite\n",
    "    def get_key(current_species, culture_item, current_XG):\n",
    "        if culture_item != 'coculture_media':\n",
    "            return '_'.join([current_species, culture_item, current_XG]) \n",
    "        return '_'.join([culture_item, current_XG]) \n",
    "    \n",
    "    file_list = ['./Data/flanalysis_BM_SG.json', './Data/flanalysis_BM_DG.json'] \n",
    "    if coculture_dict is None:\n",
    "        coculture_dict = retrive_specific_culture(file_list, culture_item=culture_item, XG=['SG','DG']) \n",
    "    flux_dict = dict()\n",
    "    for species, XG_cycle in itertools.product([E0, S0],[DG_cycle, SG_cycle]):\n",
    "        current_XG = XG_cycle.index.name\n",
    "        current_species = species.id\n",
    "        print(current_species, current_XG)\n",
    "        key = get_key(current_species, culture_item, current_XG) \n",
    "        if key not in flux_dict.keys(): # prevent repeated extraction of df for 'coculture_media'\n",
    "            flux_df = retrive_specific_keys(species, coculture_dict[key], culture_item, XG_cycle, desired_cycle_col=desired_cycle_col, alpha_table=alpha_table)\n",
    "            flux_df['Species'] = current_species\n",
    "            flux_df['XG'] = current_XG\n",
    "            flux_dict[key] = flux_df\n",
    "    # return flux_dict\n",
    "    flux_compare_df = pd.concat(flux_dict.values()).copy()\n",
    "    flux_compare_df.index.name = 'Gene_inhibition'\n",
    "#     flux_compare_df = get_ESdiff(remove_Zero_col(flux_compare_df)) # ES diff 41 columns ?only common\n",
    "#     flux_compare_df = get_Ndiff(flux_compare_df)\n",
    "    if 'lv_pairs' not in alpha_table.columns: #  alpha value not joined for checkerboard, SG format different \n",
    "        flux_compare_df = join_dfs_using_MI(get_alpha_to_merge(alpha_table), flux_compare_df, how='right') # DG only\n",
    "    flux_compare_df['culture'] =  culture_item.split('_')[0]\n",
    "    return flux_compare_df\n",
    "\n",
    "def get_SG_spec_flux(gene_list):\n",
    "    mono_dict = retrive_specific_culture(file_list, culture_item='monoculture_flux', XG=['SG','DG'])\n",
    "    Eflux_spec = retrive_specific_keys(E0, mono_dict['E0_monoculture_flux_SG'], 'monoculture_flux', desired_cycle.loc[gene_list])\n",
    "    Sflux_spec = retrive_specific_keys(S0, mono_dict['S0_monoculture_flux_SG'], 'monoculture_flux', desired_cycle.loc[gene_list])\n",
    "    return Eflux_spec, Sflux_spec\n",
    "\n",
    "def get_flux_spec(gene_list='dadX', models=[E0, S0], culture_item='coculture_flux',XG='SG'):\n",
    "    gene_list=convert_arg_to_list(gene_list)\n",
    "    result_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        flux_spec = pd.concat([\n",
    "            pd.DataFrame([f'{model.id}']*len(gene_list), index=gene_list, columns=['Species']),\n",
    "            retrive_specific_keys(model, coculture_dict[f'{model.id}_{culture_item}_{XG}'], culture_item, desired_cycle.loc[gene_list])\n",
    "        ],axis=1)\n",
    "        result_df = pd.concat([result_df, flux_spec])\n",
    "    return result_df\n",
    "\n",
    "def get_ICX_from_lv_pair_list(lv_pair_list=[4.2, 5.3]):\n",
    "    ICX = dict()\n",
    "    corrected_lv_pair_list = list()\n",
    "    for lv_pair in convert_arg_to_list(lv_pair_list):\n",
    "        lv_pair = str(lv_pair).split('.')\n",
    "        lv_pair = tuple([int(x) for x in lv_pair])\n",
    "        corrected_lv_pair_list.append(lv_pair)\n",
    "        # print(alpha_table.query('lv_pairs==@lv_pair').ICX.unique())\n",
    "        # print(lv_pair)\n",
    "        ICX.update({lv_pair: alpha_table.query('lv_pairs==@lv_pair').ICX.to_dict()})\n",
    "    return ICX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_cycle, DG_cycle = get_XG_cycle_from(desired_cycle)\n",
    "SG_cycle\n",
    "file_list = ['C:/Users/wongt/Downloads/flanalysis_checkerboard_run3.json']\n",
    "# coculture_dict = retrive_specific_culture(file_list, culture_item='coculture_flux', XG=['SG','DG'])\n",
    "# mono_dict = retrive_specific_culture(file_list, culture_item='monoculture_flux', XG=['SG','DG'])\n",
    "\n",
    "co_flux_compare_df = get_flux_compare_df('coculture_flux', coculture_dict, desired_cycle=desired_cycle, alpha_table=alpha_table) \n",
    "mono_flux_compare_df = get_flux_compare_df('monoculture_flux', mono_dict, desired_cycle=desired_cycle, alpha_table=alpha_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_pairs = [lv_pair[1].split('.') for lv_pair in flux_compare_df.index.str.split('_')]\n",
    "lv_pairs = [tuple([int(ele) for ele in lv_pair]) for lv_pair in lv_pairs]\n",
    "co_flux_compare_df['lv_pairs'] = lv_pairs\n",
    "# arrange 'Species', 'XG', 'lv_pairs' to front\n",
    "cols = co_flux_compare_df.columns.tolist()\n",
    "cols = ['Species', 'XG', 'lv_pairs'] + [col for col in cols if col not in ['Species', 'XG', 'lv_pairs']]\n",
    "flux_compare_df = co_flux_compare_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_cycle.query('culture==\"coculture\"').merge(flux_compare_df,\n",
    "#                                                   left_index=True, right_index=True)\n",
    "\n",
    "flux_compare_df = pd.concat([flux_compare_df, mono_flux_compare_df])\n",
    "flux_compare_df = join_dfs_using_MI([desired_cycle, flux_compare_df], multi_index=['XG','Gene_inhibition', 'culture','Species'])\n",
    "flux_compare_df['ICX'] = flux_compare_df.apply(lambda x : get_ICX_from_lv_pair_list(x.alpha_lv_pairs).values(), axis=1)\n",
    "# flux_compare_df.to_csv('./Data/checkerboard_flux_compare_df.csv')\n",
    "# flux_compare_df.loc[lv_pair_list][['growth_phase','EX_met__L_e','EX_lcts_e','EX_gal_e','EX_ac_e','EX_ac_e_mean','EX_ac_e_std','EX_co2_e',\n",
    "#                                                                      'DHPS2','DHFR',  'BIOMASS_Ec_iML1515_core_75p37M','BIOMASS_iRR1083_metals']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintainance flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintaince_flux = coculture_dict['E0_coculture_flux_SG']['folP.folA_5.5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible single gene format for checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     folP_0\n",
       "1     folA_0\n",
       "2     folP_0\n",
       "3     folA_1\n",
       "4     folP_0\n",
       "       ...  \n",
       "67    folA_3\n",
       "68    folP_5\n",
       "69    folA_4\n",
       "70    folP_5\n",
       "71    folA_5\n",
       "Length: 72, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_checkerboard_inhibition_SG(gene, lv_pairs):\n",
    "    # print(gene, lv_pairs)\n",
    "    mask = [gene == g for g in 'folP.folA'.split('.')]\n",
    "    if isinstance(lv_pairs, str):\n",
    "        lv_pairs =ast.literal_eval(lv_pairs)\n",
    "        \n",
    "    return ''.join([gene+'_'+str(x) for x, m in zip(lv_pairs, mask) if m]) # should be only element \n",
    "\n",
    "alpha_table.reset_index().apply(lambda x: get_checkerboard_inhibition_SG(x.Gene_inhibition, x.lv_pairs), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vR",
   "language": "python",
   "name": "vr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
