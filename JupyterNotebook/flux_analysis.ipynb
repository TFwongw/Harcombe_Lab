{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22cce5e",
   "metadata": {},
   "source": [
    "# pwy_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27298cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cobra\n",
    "import itertools\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# E0 = cobra.io.read_sbml_model(\"./models/iML1515_E0.xml\")\n",
    "# # reactions in TAC or other pathways\n",
    "\n",
    "# desired_cycle = pd.read_csv('./Data/desired_cycle.csv', index_col=0) #flux analysis.ipynb\n",
    "# gr_DG = pd.read_csv('./r/data fitting/standardized_gr_Div_DG_Mult_Aug31.csv', index_col='gene_inhibition')\n",
    "# gr_DG.loc[:,:'S0.ac_monoculture'][gr_DG.loc[:,:'S0.ac_monoculture']<1e-5] = 0 \n",
    "\n",
    "# label_df = pd.read_excel(open('./Data/iML1515_GP.xlsx', 'rb'), # ? S0 rct pathway label necessary?\n",
    "#               sheet_name='iML1515_GP', index_col=0)\n",
    "# # rct_pathway_df = pd.read_csv('./Data/rct_pathway.csv')\n",
    "# alpha_table = pd.read_csv(\"./Data/alpha_table.csv\", index_col=0)\n",
    "# comb_list = list(pd.read_csv('./Data/gr_Div_DG_Blis_Aug31.csv').gene_inhibition[1:])\n",
    "DG_list = list(gr_DG.index)\n",
    "DG_list.remove('Normal')\n",
    "genes = alpha_table.index\n",
    "\n",
    "S0 = cobra.io.read_sbml_model(\"./models/STM_v1_0_S0.xml\")\n",
    "E0.id = 'E0'\n",
    "S0.id = 'S0.ac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9df4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_arg_to_list(arg):\n",
    "    if type(arg) is pd.Series:\n",
    "        arg = list(arg) \n",
    "    elif type(arg) not in [list, tuple, set]:\n",
    "        arg = [arg] # differ from list(arg) -> conversion of str\n",
    "    return arg\n",
    "\n",
    "def get_Biomass_df(files):\n",
    "    return pd.concat(\n",
    "            [pd.read_csv(file, index_col='cycle')\n",
    "             for file in convert_arg_to_list(files)]\n",
    "        ,axis=1)\n",
    "\n",
    "Biomass_df = get_Biomass_df(['./Data/BM_SG1.csv', './Data/BM_DG1.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6285e",
   "metadata": {},
   "source": [
    "# desired cycle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade487a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 2000)\n",
    "# display(HTML(\"<style>.container { width:40% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db56df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_step=5\n",
    "\n",
    "def search_gr_cycle_with_biomass(df_search, biomass_values):\n",
    "    return [df_search[df_search >= biomass_value].idxmin() \n",
    "                for biomass_value in convert_arg_to_list(biomass_values)]\n",
    "\n",
    "def get_cycle_max_gr(desired_BM):\n",
    "    max_gr = desired_BM.iloc[-1]/2\n",
    "    bool_growing = ((desired_BM.iloc[-1]-desired_BM.iloc[-5])/desired_BM.iloc[-1]).apply(lambda x: x > 1e-10)\n",
    "    for k, bool_grow in bool_growing.items():\n",
    "        if bool_grow:\n",
    "            max_gr[k] = desired_BM[k].iloc[-6]\n",
    "    biomass_diff = (Biomass_df.iloc[-1]-Biomass_df.iloc[0])\n",
    "    start = Biomass_df.iloc[0] + biomass_diff*0.1\n",
    "    end = Biomass_df.iloc[0] + biomass_diff*0.9\n",
    "    \n",
    "    return max_gr, start, end, bool_growing\n",
    "\n",
    "def find_down_neighbour(df):\n",
    "    max_gr = get_cycle_max_gr(df)\n",
    "    position = list()\n",
    "    \n",
    "    def correct_cycle(cycle):\n",
    "        mod = cycle%log_step\n",
    "#         return cycle if mod==0 else cycle+log_step-mod # round up\n",
    "        return cycle if mod==0 else cycle-mod # round down\n",
    "#   \n",
    "    gr_cycle = defaultdict(dict)\n",
    "    for gcomb, biomass_value in max_gr.items():\n",
    "        df_search = df.loc[:,gcomb]\n",
    "        upperneighbour_ind =  search_gr_cycle_with_biomass(df_search, biomass_value) # 0 if growth belolw 1e-8 \n",
    "#         gr_cycle[gcomb] = correct_cycle(upperneighbour_ind) \n",
    "        gr_cycle[gcomb].update({'cycle': correct_cycle(upperneighbour_ind),\n",
    "                                'growth phase': [search_gr_cycle_with_biomass(),\n",
    "                                                search_gr_cycle_with_biomass()]})\n",
    "    return gr_cycle\n",
    "\n",
    "# def get_desired_cycle_df():\n",
    "#     desired_cycle_dict = defaultdict(dict)\n",
    "#     for k, cycle in find_down_neighbour(Biomass_df).items():\n",
    "#         key_items = k.split('_')\n",
    "#         gcomb = key_items.pop(1)\n",
    "#         col_name = '_'.join(key_items)\n",
    "#         if desired_cycle_dict[gcomb].get(col_name):\n",
    "#             sys.exit(\"Halt, Gene comb keys get overwritten\")\n",
    "#         desired_cycle_dict[gcomb].update({col_name: cycle})\n",
    "\n",
    "#     return pd.DataFrame.from_dict(desired_cycle_dict, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desired_cycle(desired_biomass_df):\n",
    "    def correct_cycle(cycle):\n",
    "        mod = cycle%log_step\n",
    "    #         return cycle if mod==0 else cycle+log_step-mod # round up\n",
    "        return cycle if mod==0 else cycle-mod # round down\n",
    "\n",
    "    def get_growth_phase_length():\n",
    "        return ((desired_cycle['end'] - desired_cycle['start'])*(1-desired_cycle.bool_growing) + # if not growing, not changing growth phase length\n",
    "                999*(desired_cycle.bool_growing)) #if growing, set growth length to 999\n",
    "\n",
    "    desired_cycle = (desired_biomass_df.iloc[:-1]\n",
    "                  .apply(lambda x: \n",
    "                         search_gr_cycle_with_biomass(Biomass_df.loc[:,x.name],x))\n",
    "                  .T)\n",
    "    def split_index_to_cols(df):\n",
    "        return pd.DataFrame(zip(*df.index.str.split('_')), index=['Species', 'Gene_inhibition', 'culture'], columns=df.index).T\n",
    "    desired_cycle['bool_growing'] = desired_biomass_df.T.bool_growing\n",
    "    desired_cycle['cycle_max_gr'] = desired_cycle['max_gr'].apply(correct_cycle) # -> cycle_max_gr\n",
    "    desired_cycle['growth_phase'] = desired_cycle[['start', 'end']].values.tolist()\n",
    "    desired_cycle['growth_phase_length'] = get_growth_phase_length()\n",
    "    desired_cycle = desired_cycle.join(split_index_to_cols(desired_cycle))\n",
    "#     .query('culture==\"coculture\"')\n",
    "    desired_cycle = desired_cycle.set_index('Gene_inhibition')[['cycle_max_gr', 'bool_growing', 'growth_phase_length', 'Species','culture']]\n",
    "    \n",
    "    return desired_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b394da",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_biomass_df = pd.DataFrame(get_cycle_max_gr(Biomass_df), index=['max_gr', 'start', 'end', 'bool_growing'])\n",
    "desired_cycle = get_desired_cycle(desired_biomass_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305303b",
   "metadata": {},
   "source": [
    "# PWY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_id(model, gene_name):\n",
    "    for i in model.genes:\n",
    "        if(i.name == gene_name):\n",
    "            return(i.id)\n",
    "\n",
    "def record_rct(model, current_gene):\n",
    "    return [rct.id for rct in model.genes.get_by_id(get_gene_id(model, current_gene)).reactions]\n",
    "\n",
    "def pwy_dict_to_df(pwy_dict):\n",
    "    df = pd.DataFrame.from_dict({k: ' + '.join(v) for k, v in pwy_dict.items()},\n",
    "#     df = pd.DataFrame.from_dict({k: '+'.join(v) for k, v in pwy_dict.items()},\n",
    "                       orient='index', columns=['Pathway'])\n",
    "    df.index.name = 'Gene_inhibition'\n",
    "    return df\n",
    "\n",
    "def convert_dict_to_long_df(d: dict, cols: list):\n",
    "    gcomb_pwy_list = list()\n",
    "    for gcomb, pwys in d.items():\n",
    "        for pwy in pwys:\n",
    "            gcomb_pwy_list.append([gcomb, pwy])\n",
    "#     index_col = [col for col in cols if col in 'Gene_inhibition|Reaction']\n",
    "    df = pd.DataFrame.from_records(gcomb_pwy_list, columns=cols)\n",
    "    return df\n",
    "\n",
    "def get_SG_pwy_dict(model):\n",
    "    gene_rct_dict = defaultdict(list)\n",
    "    for current_gene in alpha_table.index:\n",
    "        gene_rct_dict[f'{current_gene}'] = record_rct(model, current_gene)\n",
    "    \n",
    "    gene_pwy_dict = defaultdict(list)\n",
    "    for current_gene,rcts in gene_rct_dict.items():\n",
    "        for current_reaction in rcts:\n",
    "            try:\n",
    "                label = label_df.loc[f'{current_reaction}', 'm_subsystem']\n",
    "                label = label if type(label) == str else label[0]\n",
    "                gene_pwy_dict[f'{current_gene}'].append(label)\n",
    "            except:\n",
    "                print(current_gene, f'reaction {current_reaction} not exist in list')\n",
    "        gene_pwy_dict[f'{current_gene}'] = set(convert_arg_to_list(gene_pwy_dict[f'{current_gene}'])) | set(gene_pwy_dict[f'{current_gene}'])\n",
    "    return gene_pwy_dict\n",
    "\n",
    "def get_gene_pathway_df(model):\n",
    "    pwy_dict = get_SG_pwy_dict(model)\n",
    "    DG_pwy_dict = get_DG_pwy_dict(pwy_dict)\n",
    "    \n",
    "    pwy_dict.update(DG_pwy_dict)\n",
    "    \n",
    "    gene_pathway_df = convert_dict_to_long_df(pwy_dict, ['Gene_inhibition', 'Pathway'])\n",
    "    gene_pathway_df['XG'] = gene_pathway_df.Gene_inhibition.str.split('.').apply(\n",
    "        lambda x: 'SG' if len(x)==1 else 'DG') \n",
    "    return gene_pathway_df\n",
    "\n",
    "def antagonistic_count(genes:list):\n",
    "    antagonistic_set = ['dadX.rffG', 'dadX.pyrD', 'acnB.thrB', 'acnB.thrB', 'acnB.thrB',\n",
    "       'aroA.argD', 'aroA.argD', 'aroA.argD', 'dadX.guaB', 'aroA.dapB',\n",
    "       'aroA.guaB']\n",
    "    return list((set(genes).intersection(antagonistic_set)))\n",
    "\n",
    "def get_ratio_col(gene_count_df):\n",
    "    DG = gene_count_df.query('XG==\"DG\"').reset_index(drop=True).copy()\n",
    "    DG['Antagonistic_gcomb'] = DG.Gene_list.apply(lambda x: antagonistic_count(x.split(', ')))\n",
    "#     DG['Antagonistic_ratio'] = DG.Antagonistic_gcomb.str.split(', ').map(len)\n",
    "    DG['Antagonistic_ratio'] = pd.Series(map(len, DG.Antagonistic_gcomb.tolist()))/DG.Gene_count\n",
    "    DG['Antagonistic_gcomb'] = DG['Antagonistic_gcomb'].apply(lambda x: ', '.join(x))\n",
    "    \n",
    "    return DG[['Pathway', 'Antagonistic_ratio', 'Antagonistic_gcomb']]\n",
    "\n",
    "def get_gene_count_df(gene_pathway_df):\n",
    "\n",
    "    gene_count_df = (gene_pathway_df.groupby(['Pathway','XG'], as_index=False).agg(\n",
    "                        Gene_list=('Gene_inhibition', lambda x: ', '.join(x.values)),\n",
    "                        Gene_count=('Gene_inhibition', 'count')))\n",
    "    gene_count_df = gene_count_df.merge(get_ratio_col(gene_count_df), on='Pathway')\n",
    "    (gene_count_df.pivot(index=['Pathway','Antagonistic_ratio', 'Antagonistic_gcomb'], columns=['XG'], values=['Gene_list','Gene_count'])\n",
    "         .sort_values(by=('Gene_count','DG'), ascending=False)).to_csv('./Data/gene_count.csv')\n",
    "    return gene_count_df\n",
    "\n",
    "def get_single_pathway_df(gene_pathway_df):\n",
    "    # add p_o afterwards\n",
    "    df = (gene_pathway_df.groupby(['Gene_inhibition','XG'], as_index=False).agg(\n",
    "        Pathway_count=('Pathway', 'count'),\n",
    "        Pathway_list = ('Pathway', lambda x: list(x.values))))\n",
    "#         P = ('Pathway', lambda x: pd.DataFrame(x.values))))\n",
    "    df['Single_pathway'] = pd.cut(df['Pathway_count'], [0,1,10], labels = ['Single_pathway', 'Multi_pathway'])\n",
    "    return df.sort_values(['Pathway_count', 'XG'], ascending=True).set_index('Gene_inhibition')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce808eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rct_pathway_df():\n",
    "    pwy_rct_dict = defaultdict(list)\n",
    "    for index, sub_df in label_df[['m_subsystem']].iterrows():\n",
    "        pwy_rct_dict[sub_df[0]].append(index)\n",
    "    rct_pathway_df = convert_dict_to_long_df(pwy_rct_dict,['Pathway','Reaction'])\n",
    "    return rct_pathway_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d18551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DG_pwy_dict(SG_pwy_dict):\n",
    "    comb_list = list(pd.read_csv('./Data/gr_Div_DG_Blis_Aug31.csv').gene_inhibition[1:])\n",
    "    DG_pwy_dict = dict()\n",
    "    # for DG_pwy in comb_list:\n",
    "    gene_pathway_row = list()\n",
    "    for DG_pwy in comb_list:\n",
    "        gene_pair = DG_pwy.split('.')\n",
    "        DG_pwy_dict[DG_pwy] = SG_pwy_dict[gene_pair[0]] | SG_pwy_dict[gene_pair[1]] \n",
    "    return DG_pwy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "rct_pathway_df = get_rct_pathway_df()\n",
    "gene_pathway_df = get_gene_pathway_df(E0)\n",
    "\n",
    "gene_count_df=get_gene_count_df(gene_pathway_df)\n",
    "single_pathway_df = get_single_pathway_df(gene_pathway_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c121a",
   "metadata": {},
   "source": [
    "# p_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce88071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syn_df(gr_XG, model):\n",
    "    model_id = model.id\n",
    "    additive_threshold = .01\n",
    "    diff_bins = [-10,-1*additive_threshold,1*additive_threshold,10]\n",
    "    gr_bins = [-1,.2,1,10]\n",
    "    \n",
    "    if gr_XG.index.name == 'gene_inhibition':\n",
    "        gr_XG.index.name = 'Gene_inhibition'\n",
    "    syn_df  = pd.DataFrame([], index=gr_DG.index)\n",
    "    syn_df['Predicted_growth_rate'] = gr_XG[f'Predicted_additive_effect_{model.id}_coculture']\n",
    "    syn_df['Observed_growth_rate'] = gr_XG[f'{model.id}_coculture']\n",
    "    syn_df['P_O'] = syn_df.Predicted_growth_rate - syn_df.Observed_growth_rate\n",
    "    syn_df['Drug_comb_effect'] = pd.cut(syn_df['P_O'], bins=diff_bins, labels=['Antagonistic', 'Additive', 'Synergistic'])\n",
    "    \n",
    "    syn_df['PGR_bin'] = pd.cut(syn_df['Predicted_growth_rate'], bins=gr_bins, labels=['Low', 'Normal', 'High'])\n",
    "    syn_df['OGR_bin'] = pd.cut(syn_df['Observed_growth_rate'], bins=gr_bins, labels=['Low', 'Normal', 'High'])\n",
    "    \n",
    "    syn_df.loc[(syn_df.Predicted_growth_rate < 1.5e-8) & (syn_df.Observed_growth_rate < 1.5e-8),'P_O'] = 0\n",
    "    syn_df['gene_sort'] = (syn_df['P_O'] < 0)*10 + abs(syn_df['P_O'])\n",
    "    syn_df['Species'] = model.id\n",
    "    return syn_df\n",
    "\n",
    "def get_antagonistic_df(syn_df):\n",
    "    antagonistic_list = syn_df.loc[syn_df['P_O']<0].query(\"P_O<-0.01\").index \n",
    "    # ? func get pwy col\n",
    "    potential_pwy = (gene_combo_pathway\n",
    "                                      .loc[antagonistic_list,'Pathway']\n",
    "                                      .str.split(' \\+ ') # series string need \\+\n",
    "                                      .apply(lambda x: sorted(x))) \n",
    "    return pd.DataFrame(potential_pwy)\n",
    "\n",
    "def remove_nan_from(x: pd.Series):\n",
    "    return x.apply(lambda x: sorted(list(itertools.compress(x,[ele not in [None, np.nan] for ele in x]))))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_o_df():\n",
    "    single_pathway_df = pd.read_csv('./Data/single_pathway_df.csv')\n",
    "    gcomb_single_pathway_df = single_pathway_df.query('XG==\"DG\"') # select only DG\n",
    "    p_o = pd.concat([get_syn_df(gr_DG, E0), get_syn_df(gr_DG, S0)])\n",
    "    p_o = p_o.merge(gcomb_single_pathway_df.drop('XG', axis=1), left_index=True, right_on='Gene_inhibition', how='outer')\n",
    "    return p_o.set_index('Gene_inhibition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eeda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_o_full = get_p_o_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d1265",
   "metadata": {},
   "source": [
    "# flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_id(model, gene_name):\n",
    "    for i in model.genes:\n",
    "        if(i.name == gene_name):\n",
    "            return(i.id)\n",
    "\n",
    "def get_rcts_list(model, gcomb_list): \n",
    "    rcts_list = list()\n",
    "    rcts_set = set()\n",
    "    for i, gene in enumerate(gcomb_list):\n",
    "        gene_rcts = [rct.id for rct in model.genes.get_by_id(get_gene_id(model, gene)).reactions]\n",
    "        if i > 0:\n",
    "            gene_rcts = list(set(gene_rcts) - rcts_set)\n",
    "        rcts_list.append(gene_rcts)\n",
    "        rcts_set = rcts_set | set(gene_rcts)\n",
    "    return rcts_list\n",
    "\n",
    "def adjust_flux_df(model, df, gene_combo: list):\n",
    "    if 'Normal' not in gene_combo:\n",
    "#         gene_combo_dict = get_gcomb_alpha_dict(gene_combo) \n",
    "        v1_cols = df.filter(regex='v1').columns\n",
    "        orig_cols = [ele.replace(\"_v1\", '') for ele in df.filter(regex='v1').columns]\n",
    "        \n",
    "        gene_combo_list = gene_combo.split('.')\n",
    "        rcts_list = get_rcts_list(model, gene_combo_list)\n",
    "        scaled_rcts = list()\n",
    "        for gene, rcts in zip(gene_combo_list, rcts_list):  \n",
    "            rcts = [rct for rct in rcts if rct in orig_cols]\n",
    "            for orig_col in rcts:\n",
    "                alpha = alpha_table.loc[f'{gene}', f'{model.id}']   \n",
    "                v1_col = orig_col + \"_v1\"\n",
    "                df[f'{orig_col}'] = (df[f'{orig_col}'] + df[f'{v1_col}'])/alpha # only forward or backward != 0               \n",
    "                df = df.drop(f'{v1_col}', axis=1) \n",
    "#     print(df.filter(regex='v1').columns)\n",
    "    return df\n",
    "\n",
    "def get_desired_BM(Biomass_df = Biomass_df, regex='Normal_coculture'):\n",
    "    return Biomass_df.filter(regex=regex)\n",
    "  \n",
    "def supply_line(file):\n",
    "#     file = f'./Data/{file}'\n",
    "    with open(file) as fh:\n",
    "        for line in fh:\n",
    "            yield json.loads(line) \n",
    "\n",
    "def retrive_specific_culture(file_list: list, culture_item: str, XG = 'DG'): # culture_item: 'coculture_flux'\n",
    "    def modify_culture_dict_keys(k: str, XG: str):\n",
    "        k_list = k.split('_')\n",
    "        k_list[:-2] =  ['.'.join(k_list[:-2])]\n",
    "        k_list.append(XG)\n",
    "        return '_'.join(k_list)\n",
    "#     culture_item = 'E0_coculture_flux'\n",
    "    flux_dict = dict()\n",
    "    culture_dict = dict()\n",
    "    \n",
    "    for file, current_XG in zip(convert_arg_to_list(file_list), convert_arg_to_list(XG)):\n",
    "        supp = supply_line(file)\n",
    "        culture_items = [f'E0_{culture_item}', f'S0_ac_{culture_item}'] # prefix in json \n",
    "        for line in supp:    # culture as column <=> keys\n",
    "    #         culture_dict = line.get(f'{culture_item}')\n",
    "            if any([ele in line.keys() for ele in culture_items]):\n",
    "                culture_dict.update(\n",
    "                    {modify_culture_dict_keys(k, current_XG): v \n",
    "                     for k, v in line.items() if k in culture_items}) \n",
    "    return culture_dict # {E0_coculture: Dict, S0_coculture: Dict}\n",
    "\n",
    "# pwy group with more than 2 element\n",
    "def get_pwypair_gp_GRT2(p_o: dict): # index greater than 2 element\n",
    "    flux_compare_combos_dict = {k:v for k,v in p_o.items() if len(v)>=2}\n",
    "    return flux_compare_combos_dict\n",
    " \n",
    "def retrive_specific_keys(model, file: List[str]|str, culture_item, desired_cycle):\n",
    "    def get_flux_dict(culture_dict, model, desired_cycle):\n",
    "#         if model.id in culture_dict.keys(): # ?delete?\n",
    "#             culture_dict = culture_dict[model.id]\n",
    "        flux_dict, no_grow = dict(), list()\n",
    "        culture = culture_item.split('_')[0]\n",
    "#         for current_gene_combo, cycle in desired_cycle[[f'{model.id}_{culture}']].iterrows():\n",
    "        for current_gene_combo, cycle_row in desired_cycle.query('Species == @model.id & culture == @culture').iterrows():\n",
    "#         for current_gene_combo, cycle in desired_cycle.iterrows():\n",
    "            \n",
    "#             cycle = cycle[0] # iterrow create subdata frame of one column \n",
    "            cycle = cycle_row['cycle_max_gr'] # iterrow create subdata frame of one column \n",
    "            if cycle < 15:\n",
    "                no_grow.append(current_gene_combo)\n",
    "                flux_dict[current_gene_combo] = pd.DataFrame([], index = [f'{current_gene_combo}'])\n",
    "            else:\n",
    "                desired_js = culture_dict.get(f'{current_gene_combo}')\n",
    "                temp_df = pd.read_json(desired_js).query(\"cycle == @cycle\")\n",
    "                temp_df.index = [current_gene_combo]\n",
    "        #                 return temp_df, current_gene_combo\n",
    "                flux_dict[current_gene_combo] = adjust_flux_df(model, temp_df, current_gene_combo) # df as \n",
    "        #             genes_dict = {current_gene_combo: genes_dict.get(f'{current_gene_combo}') for current_gene_combo in genes_dict}  #subset of gene\n",
    "        if no_grow:\n",
    "            print('Zero growth: ', ', '.join(no_grow))\n",
    "        return pd.concat(flux_dict.values()).copy() # pd.read_json() culture_item -> col pd.read_json()\n",
    "#         return pd.concat(flux_dict.values()) # pd.read_json() culture_item -> col pd.read_json()\n",
    "    \n",
    "#     print(type(file) is dict)\n",
    "    if type(file) is dict:\n",
    "        return get_flux_dict(file, model, desired_cycle)\n",
    "    else: # list of filename, str filename\n",
    "        culture_dict = retrive_specific_culture(file, culture_item)\n",
    "        return get_flux_dict(culture_dict, model, desired_cycle) \n",
    "    \n",
    "def remove_Zero_col(df): # extend N differ than 0 \n",
    "    return(df.loc[:, ((df !=0) & (df.notnull())).any(axis=0)]) # ignore NA entry \n",
    "\n",
    "def clean_flux_df(df):\n",
    "    return remove_Zero_col(df.dropna())\n",
    "\n",
    "def get_XG_cycle_from(desired_cycle):\n",
    "    SG_cycle = desired_cycle.loc[[len(ele.split('.')) ==1 for ele in desired_cycle.index]]\n",
    "    DG_cycle = desired_cycle.loc[[len(ele.split('.')) >=2 for ele in desired_cycle.index]]\n",
    "    SG_cycle.index.name='SG'\n",
    "    DG_cycle.index.name='DG'\n",
    "    SG_cycle.columns.name=None\n",
    "    DG_cycle.columns.name=None    \n",
    "    return SG_cycle, DG_cycle    \n",
    "alpha_table.columns = ['E0', 'S0.ac', 'S0.glc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd248b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SG_DG(explode=True):\n",
    "    df = pd.DataFrame(pd.DataFrame(2*[DG_list], index=['Gene_inhibition','SG']).T.set_index('Gene_inhibition').SG.str.split('.'))\n",
    "    return df.explode() if explode else df\n",
    "   \n",
    "def get_alpha_wide():\n",
    "    return alpha_table.melt(value_vars=['E0', 'S0.ac'], var_name='Species', value_name='alpha', ignore_index=False)\n",
    "\n",
    "def get_alpha_to_merge():\n",
    "    def get_alpha(l: list[str, str]):\n",
    "        l=l[0]\n",
    "    #     print(l)\n",
    "        Species = [E0.id, S0.id]\n",
    "        df = pd.DataFrame(alpha_table.loc[l, Species]).T\n",
    "        return df.values.tolist()\n",
    "    # a.apply(get_alpha, axis=1, result_type='broadcast')\n",
    "\n",
    "    ES_cols = ['E0', 'S0.ac']\n",
    "    alpha_wide = get_alpha_wide()\n",
    "    df = (get_SG_DG(explode=False)\n",
    "          .apply(lambda x: pd.Series(get_alpha(x), index=ES_cols), axis=1) # df with E0 S0 alpha columns\n",
    "          .melt(value_vars=ES_cols, var_name='Species', value_name='alpha', ignore_index=False)\n",
    "          .combine_first(alpha_wide))\n",
    "    return df\n",
    "alpha_to_merge = get_alpha_to_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_GI_SP_as_MI(end_BM, manual_SI = False):\n",
    "    if type(end_BM.index[0]) is not int: # Gene_inhibition is not index # Series.dtype -> dtype('int64')\n",
    "        if end_BM.index.name in [None, 'DG']:\n",
    "            end_BM.index.name = 'Gene_inhibition'\n",
    "        if end_BM.index.name == 'Gene_inhibition':\n",
    "            end_BM = end_BM.reset_index()\n",
    "    if 'Species' in end_BM.columns and manual_SI == False:\n",
    "        return end_BM.set_index(['Gene_inhibition', 'Species'])\n",
    "    else:\n",
    "        return end_BM.set_index('Gene_inhibition')\n",
    "\n",
    "def join_dfs_using_MI(df1, df2, how='left'):\n",
    "    return set_GI_SP_as_MI(df1).join(set_GI_SP_as_MI(df2), how=how)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738472da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flux_compare_df(culture_item,culture_dict, SG_cycle, DG_cycle):\n",
    "    file_list = ['./Data/flanalysis_BM_SG.json', './Data/flanalysis_BM_DG.json'] \n",
    "    culture_dict = retrive_specific_culture(file_list, culture_item=culture_item, XG=['SG','DG'])  \n",
    "    flux_dict = dict()\n",
    "    for species, XG_cycle in itertools.product([E0, S0],[DG_cycle, SG_cycle]):\n",
    "        current_XG = XG_cycle.index.name\n",
    "        current_species = species.id\n",
    "        print(current_species, current_XG)\n",
    "\n",
    "        key = '_'.join([current_species, culture_item, current_XG])\n",
    "\n",
    "        flux_df = retrive_specific_keys(species, culture_dict[key], culture_item, XG_cycle)\n",
    "        flux_df['Species'] = current_species\n",
    "        flux_df['XG'] = current_XG\n",
    "        flux_dict[(current_species, current_XG)] = flux_df\n",
    "    flux_compare_df = pd.concat(flux_dict.values()).copy()\n",
    "    flux_compare_df.index.name = 'Gene_inhibition'\n",
    "#     flux_compare_df = get_ESdiff(remove_Zero_col(flux_compare_df)) # ES diff 41 columns ?only common\n",
    "#     flux_compare_df = get_Ndiff(flux_compare_df)\n",
    "    flux_compare_df = join_dfs_using_MI(get_alpha_to_merge(), flux_compare_df, how='right') # DG only\n",
    "    return flux_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['./Data/flanalysis_BM_SG.json', './Data/flanalysis_BM_DG.json']\n",
    "culture_dict = retrive_specific_culture(file_list, culture_item='coculture_flux', XG=['SG','DG'])\n",
    "SG_cycle, DG_cycle = get_XG_cycle_from(desired_cycle)\n",
    "# flux_compare_df = get_flux_compare_df('coculture_flux', culture_dict, SG_cycle, DG_cycle) \n",
    "flux_compare_df = pd.read_csv('./Data/flux_compare_df.csv')\n",
    "# flux_compare_df.to_csv('./Data/flux_compare_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f57d2e",
   "metadata": {},
   "source": [
    "# Reaction column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adacb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SG_pwy_df():\n",
    "    SG_pwy_df = pd.DataFrame.from_dict(get_SG_pwy_dict(E0), orient='index')\n",
    "    SG_pwy_df['Pathways'] = SG_pwy_df.values.tolist()\n",
    "    SG_pwy_df = pd.DataFrame(remove_nan_from(SG_pwy_df.Pathways))\n",
    "#     SG_pwy_df = pd.DataFrame(SG_pwy_df.Pathways\n",
    "#                              .apply(lambda x: remove_nan_from(x)))\n",
    "    SG_pwy_df['E0_Reactions'] = list(pd.Series(SG_pwy_df.index).apply(lambda x: record_rct(E0,x)))\n",
    "    SG_pwy_df['S0_Reactions'] = list(pd.Series(SG_pwy_df.index).apply(lambda x: record_rct(S0,x)))    \n",
    "    return SG_pwy_df\n",
    "\n",
    "def find_reactions_not_exist_in(model, reactions: list):\n",
    "    if len(reactions) ==0:\n",
    "        return reactions\n",
    "    reactions = convert_arg_to_list(reactions)\n",
    "    reactions_all = [rct.id for rct in model.reactions]\n",
    "    not_found_reactions = [rct for rct in reactions if rct not in reactions_all]\n",
    "    return not_found_reactions\n",
    "\n",
    "def get_pwy_rct_df(DG_list):\n",
    "    def get_pwys_from(SG_pwy_df, SG):\n",
    "        return SG_pwy_df.loc[SG, 'Pathways']\n",
    "    \n",
    "    g_pwy_rct_df = pd.DataFrame(DG_list, columns=['DG'])\n",
    "    g_pwy_rct_df['SG_list'] =  g_pwy_rct_df.apply(lambda x: x.DG.split('.'), axis=1)\n",
    "    g_pwy_rct_df['Pathways'] = g_pwy_rct_df.apply(lambda x: list(set(SG_pwy_df.loc[x.SG_list[0],'Pathways']) | set(SG_pwy_df.loc[x.SG_list[1],'Pathways'])), axis=1)\n",
    "    g_pwy_rct_df['Common_pathway'] = g_pwy_rct_df.apply(lambda x: set(get_pwys_from(SG_pwy_df, x.SG_list[0]))\n",
    "                                                        .intersection(set(get_pwys_from(SG_pwy_df, x.SG_list[1])))\n",
    "                                                        ,axis=1)\n",
    "    g_pwy_rct_df['Reactions_E0'] = g_pwy_rct_df.apply(\n",
    "        lambda x: list(set(SG_pwy_df.loc[x.SG_list[0],'E0_Reactions']) | set(SG_pwy_df.loc[x.SG_list[1],'E0_Reactions'])), axis=1)\n",
    "    g_pwy_rct_df['Reactions_S0'] = g_pwy_rct_df.apply(\n",
    "        lambda x: list(set(SG_pwy_df.loc[x.SG_list[0],'S0_Reactions']) | set(SG_pwy_df.loc[x.SG_list[1],'S0_Reactions'])), axis=1)\n",
    "    g_pwy_rct_df['Common_Reactions'] = g_pwy_rct_df.apply(lambda x: set(x['Reactions_E0']).intersection(set(x['Reactions_S0'])), axis=1)\n",
    "    g_pwy_rct_df['Reactions_E0_only'] = g_pwy_rct_df.apply(lambda x: set(x['Reactions_E0'])-set(x['Reactions_S0']), axis=1)\n",
    "    g_pwy_rct_df['Reactions_S0_only'] = g_pwy_rct_df.apply(lambda x: set(x['Reactions_S0'])-set(x['Reactions_E0']), axis=1)\n",
    "    g_pwy_rct_df['Reactions_not_in_S0'] = g_pwy_rct_df.apply(lambda x: find_reactions_not_exist_in(S0, x.Reactions_E0_only), axis=1)\n",
    "    g_pwy_rct_df['Reactions_not_in_E0'] = g_pwy_rct_df.apply(lambda x: find_reactions_not_exist_in(E0, x.Reactions_S0_only), axis=1)\n",
    "    return g_pwy_rct_df.set_index('DG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_pwy_df = get_SG_pwy_df()\n",
    "DG_list = [ele for ele in set(desired_cycle.index) if len(ele.split('.')) >=2]\n",
    "pwy_rct_df = get_pwy_rct_df(DG_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4b926",
   "metadata": {},
   "source": [
    "# BM to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ea3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BM_bin(BM): # separate S0 E0 bin, combine again\n",
    "    sub_BM = BM.pivot(columns='Species', values='Biomass') #merge gene and species\n",
    "    sub_BM['S0_BM_bin'] =  pd.cut(sub_BM['S0.ac'], [-1,.001,.0025,1], labels = ['Low', 'Medium','High'])\n",
    "    sub_BM['E0_BM_bin'] =  pd.cut(sub_BM['E0'], [-1,.001,.0065,1], labels = ['Low', 'Medium','High'])\n",
    "    return sub_BM.melt(value_vars=['S0_BM_bin','S0_BM_bin'],value_name='BM_bin',ignore_index=False).BM_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_BM():\n",
    "    BM = pd.DataFrame(Biomass_df.loc[:, [col for col in Biomass_df.columns if 'coculture' in col]].iloc[-1]\n",
    "                     ).rename(columns={350:'Biomass'})\n",
    "    BM['Species'] = list(pd.Series(BM.index).apply(lambda x: str(x).split('_')[0]))\n",
    "    BM['Gene_inhibition'] = list(pd.Series(BM.index).apply(lambda x: str(x).split('_')[1]))\n",
    "    BM = BM.set_index(['Gene_inhibition'])\n",
    "    BM['Total_BM'] = BM.groupby('Gene_inhibition').Biomass.sum()\n",
    "\n",
    "    BM['Total_BM_bin'] = pd.cut(BM['Total_BM'], [-1,.004,.008,1], labels = ['Low', 'Medium','High'])\n",
    "    BM['BM_bin'] = get_BM_bin(BM)\n",
    "    return BM\n",
    "\n",
    "def separate_Species_df(df, model, inc_Species = False):\n",
    "    df = df.loc[:,~df.columns.str.contains('Ndiff|ESdiff')]\n",
    "    temp_df = pd.concat([df['Species'],df.select_dtypes(include = ['float'])], axis=1)\n",
    "    def get_species_loc(model):\n",
    "        return list(temp_df.Species == model.id)\n",
    "    result_df = temp_df.loc[get_species_loc(model)]\n",
    "    return result_df if inc_Species else result_df.drop('Species',axis=1)\n",
    "\n",
    "def add_to_end_BM():\n",
    "    def get_ratioNstd_col(model):\n",
    "        temp_df = separate_Species_df(end_BM, model, inc_Species=True)\n",
    "#         temp_df[f'{model.id}_BM_ratio'] = temp_df.Biomass/temp_df.Total_BM\n",
    "#         temp_df[f'{model.id}_standardized_BM'] = temp_df.Biomass/temp_df.loc['Normal', 'Biomass']\n",
    "        temp_df[f'BM_consortia_frac'] = temp_df.Biomass/temp_df.Total_BM\n",
    "        temp_df[f'standardized_BM'] = temp_df.Biomass/temp_df.loc['Normal', 'Biomass']\n",
    "        return temp_df\n",
    "    return pd.concat([get_ratioNstd_col(E0), get_ratioNstd_col(S0)]).set_index('Species', append=True).drop(['Total_BM', 'Biomass'], axis=1)\n",
    "\n",
    "end_BM = get_end_BM()\n",
    "end_BM = set_GI_SP_as_MI(add_to_end_BM()).join(set_GI_SP_as_MI(end_BM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30724a1e",
   "metadata": {},
   "source": [
    "# Merge all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99361dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_dfs_using_MI(merged_df, next_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd81180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_df(): # Missing desired_cycle\n",
    "    df_list = [p_o_full, end_BM, pwy_rct_df, flux_compare_df]\n",
    "    merged_df = df_list.pop(0)\n",
    "    for i, next_df in enumerate(df_list):\n",
    "        manual_SI = False\n",
    "        if 'Species' not in next_df:\n",
    "            manual_SI = True\n",
    "        merged_df = (set_GI_SP_as_MI(merged_df)\n",
    "                     .join(set_GI_SP_as_MI(next_df), how='left')) # left join->DG only\n",
    "        # inner_join SG info from desired cycle & alpha & flux\n",
    "    return merged_df.reset_index(level='Species')\n",
    "\n",
    "full_df = get_full_df() # full_df.loc[:,'Predicted_growth_rate':'Reactions_not_in_E0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e52768",
   "metadata": {},
   "source": [
    "# query spec reaction flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate flux difference between Normal and between E&S\n",
    "def get_Ndiff(df, merged = True):\n",
    "    result_df = pd.concat([separate_Species_df(df, E0, inc_Species=True), separate_Species_df(df, S0, inc_Species=True)])\n",
    "    return set_GI_SP_as_MI(df).join(set_GI_SP_as_MI(result_df), rsuffix='_Ndiff') if merged else result_df\n",
    "def get_ESdiff(df, merged = True):\n",
    "    ESdiff = separate_Species_df(df, E0) - separate_Species_df(df, S0)\n",
    "    return df.merge(ES_flux_diff, left_index=True, right_index=True, suffixes=[None, '_ESdiff']) if merged else ESdiff\n",
    "\n",
    "def get_main_role(df, colname='Normal'):\n",
    "    return pd.DataFrame(df.apply(lambda x: 'Equal' if x.max()/1.3 < x.min() else x.idxmax()), columns=convert_arg_to_list(colname))\n",
    "Normal_main_role = full_df.query(\"index=='Normal'\").set_index('Species').select_dtypes(include = ['float']).dropna(axis=1)\n",
    "Normal_main_role = get_main_role(Normal_main_role)\n",
    "\n",
    "def classify_main_role_diff(df):\n",
    "    if df.loc['Query'] > df.loc['Normal']:\n",
    "        return 'E0'  \n",
    "    if df.loc['Query']== df.loc['Normal']:\n",
    "        return 'Role not change'\n",
    "    return 'S0'\n",
    "\n",
    "def add_main_role_diff_cols(gene_list, query_list_rct=None): # df = add_main_role_diff_cols(DG_list)\n",
    "    out_dict = {'Normal': [[],[]]}\n",
    "    for current_gene in convert_arg_to_list(gene_list):\n",
    "        check_main_role = get_query_sub_df(full_df, current_gene, query_list_rct=query_list_rct, RCT_only=True, inc_Normal=False).set_index('Species').dropna() # same to higher\n",
    "        main_role_diff = (get_main_role(check_main_role, 'Query')\n",
    "                          .join(Normal_main_role)\n",
    "#                           .apply(lambda x: (x.loc['Query']!=x.loc['Normal']) & (x.loc['Query']!='Equal') & (x.loc['Normal']!='Equal'),axis=1))\n",
    "                          .apply(lambda x: classify_main_role_diff(x), axis=1))\n",
    "        main_role_diff = main_role_diff[lambda x: x != 'Role not change']\n",
    "        diff_list = list(main_role_diff.index) # Differ index\n",
    "#         diff_count = sum(main_role_diff)\n",
    "#         rct_len = len(main_role_diff)\n",
    "#         GI_switch_main_role = diff_count/rct_len\n",
    "        diff_how = list(main_role_diff)\n",
    "        out_dict[current_gene] = [diff_list, diff_how]\n",
    "#         out_dict[current_gene] = [diff_list, diff_count, rct_len, GI_switch_main_role]\n",
    "#     result_df = pd.DataFrame([diff_list, [diff_count]], columns=current_gene,index=['GI_diff_rct', 'GI_diff_count']).T\n",
    "#     result_df = pd.DataFrame.from_dict(out_dict, orient='index', columns=['GI_diff_rct', 'GI_diff_count', 'GI_rct_count', 'GI_percent_switched'])\n",
    "    result_df = pd.DataFrame.from_dict(out_dict, orient='index', columns=['GI_diff_rct', 'GI_whos_role_increased'])\n",
    "    result_df.index.name = 'Gene_inhibition'\n",
    "    return result_df\n",
    "\n",
    "def get_diff_analysis_df(gene_list, query_list_rct=None):\n",
    "    df = add_main_role_diff_cols(gene_list, query_list_rct)\n",
    "    df = (df.join(full_df[[ # np.array(full_df.loc[:,:'Reactions_not_in_E0'].columns)\n",
    "        'Species','BM_consortia_frac', 'standardized_BM','Total_BM','Total_BM_bin','Drug_comb_effect',\n",
    "        'Observed_growth_rate', 'Pathways']]))\n",
    "    df['group'] = df.groupby('Gene_inhibition').ngroup()\n",
    "    df = df.sort_values(['Drug_comb_effect','group']).drop('group', axis=1)\n",
    "#     df.to_csv('test.csv')\n",
    "    return df\n",
    "# diff_analysis_df = get_diff_analysis_df()\n",
    "\n",
    "def get_full_cols(upto = 'Reactions_not_in_E0'):\n",
    "    return np.array(full_df.loc[:,:upto].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22cbc9",
   "metadata": {},
   "source": [
    "# CTC cycle reaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ed776",
   "metadata": {},
   "outputs": [],
   "source": [
    "rct_pathway_df = pd.read_csv('./Data/rct_pathway.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAC_rct_list = rct_pathway_df.query('Pathway == \"Citric Acid Cycle\"').Reaction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c456e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAC_rct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2316dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_sub_df(full_df, query_list, query_list_rct=None, RCT_only=False, inc_Normal=True): # ['dadX.mrdA', 'dadX.pyrD']\n",
    "    if type(full_df.index) is pd.MultiIndex: # free one level\n",
    "        full_df = full_df.reset_index(level='Species')\n",
    "    query_list = convert_arg_to_list(query_list)\n",
    "    if query_list_rct is None:\n",
    "        query_list_rct = list()\n",
    "        for query in query_list:\n",
    "            query_list_rct.append(list(set(pwy_rct_df.loc[query, 'Reactions_E0']).intersection(set(full_df.columns)))) # pwy_rct_df specific to  E0 pathway\n",
    "        query_list_rct = list(set(itertools.chain(*query_list_rct)))\n",
    "    else:\n",
    "        query_list_rct = [rct for rct in TAC_rct_list if rct in full_df.columns]\n",
    "\n",
    "#     desired_cols = full_df.loc[:,'Predicted_growth_rate':'Reactions_not_in_E0'] if not RCT_only else pd.DataFrame([])\n",
    "    desired_cols = full_df.loc[:,:'Reactions_not_in_E0'] if not RCT_only else full_df[['Species']]\n",
    "    desired_cols = list(itertools.chain(*[desired_cols, query_list_rct]))\n",
    "#     result_df = pd.join([result_df, full_df.loc[list(itertools.chain(*[['Normal'],query_list])), query_list_rct]])\n",
    "    if inc_Normal:\n",
    "        query_list = itertools.chain(*[['Normal'], query_list])\n",
    "    return full_df.loc[query_list,desired_cols]\n",
    "# get_query_sub_df(full_df, DG_list, )\n",
    "\n",
    "\n",
    "# TCA_diff_df = get_diff_analysis_df(DG_list, TAC_rct_list)\n",
    "TCA_diff_df = add_main_role_diff_cols(DG_list, TAC_rct_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9000cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_diff_analysis_df(DG_list, TAC_rct_list)\n",
    "a.sort_values('Total_BM_bin').to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025306a1",
   "metadata": {},
   "source": [
    "# plot coculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4af1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_coculture(gene_list):\n",
    "    colnames = list()\n",
    "    for model, current_gene in itertools.product([E0, S0],gene_list):\n",
    "        colnames.append('_'.join([model.id, current_gene, 'coculture']))\n",
    "    \n",
    "    Biomass_df[colnames].plot()\n",
    "    return Biomass_df[colnames]\n",
    "# plot_coculture(['dadX.pyrD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8238f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[94mkl\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kl' is not defined"
     ]
    }
   ],
   "source": [
    "kl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vR",
   "language": "python",
   "name": "vr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
